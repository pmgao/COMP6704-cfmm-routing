# CFMM Routing Experiments

This repository collects the scripts and supporting assets that we used to study routing problems across collections of constant function market makers (CFMMs). It contains utilities for generating synthetic liquidity pool data, solving a network-wide optimal routing problem using convex optimisation, and plotting solver behaviour across a range of benchmarks.

The code was originally authored by Wenxing Duan, Peimin Gao, Hiu Long Lee, and Yulin Zhou.

## Repository layout

| Path | Description |
| --- | --- |
| [`generate_cfmm_dataset.py`](generate_cfmm_dataset.py) | Command line tool that synthesises CFMM pool networks and experiment metadata. |
| [`large_example.py`](large_example.py) | End-to-end example that loads a dataset, formulates the routing problem in CVXPY, and solves it with a selected convex solver. |
| [`plot_iter_cla.py`](plot_iter_cla.py) <br> [`plot_iter_ecos.py`](plot_iter_ecos.py) <br> [`plot_iter_scs.py`](plot_iter_scs.py) <br> [`plot_iter_mosek.py`](plot_iter_mosek.py) | Utilities that parse stored solver logs and visualise convergence behaviour for Clarabel, ECOS, SCS, and MOSEK respectively. |
| [`compare.py`](compare.py) | Creates solver runtime comparison plots from hand-recorded benchmark data. |
| [`input/`](input/) | Example datasets emitted by the generator. |
| [`output/`](output/) | Cached figures generated by the plotting scripts. |

## Prerequisites

* Python ≥ 3.9.
* [`virtualenv`](https://virtualenv.pypa.io/) or any other environment manager.
* [`cvxpy`](https://www.cvxpy.org/) and its optional solver back-ends. The problem data included in the repository was primarily solved with MOSEK, ECOS, SCS, and Clarabel.
* `numpy` and `matplotlib` for numerical work and plotting.

To reproduce the authors' environment on Ubuntu, run:

```bash
sudo apt install python3-virtualenv
virtualenv venv
source venv/bin/activate
pip install numpy matplotlib cvxpy
pip install "cvxpy[CBC,CVXOPT,GLOP,GLPK,GUROBI,MOSEK,PDLP,SCIP,XPRESS,SCS,CLARABEL,QOCO,ECOS]"
```

> **Note**
> Some commercial solvers (e.g. MOSEK, GUROBI) require separate licenses. Install only the extras you have access to.

## Generating synthetic CFMM datasets

`generate_cfmm_dataset.py` produces JSON files that match the schema of the datasets used in the [angeris/cfmm-routing-code](https://github.com/angeris/cfmm-routing-code) project. Its CLI exposes controls over pool composition, depths, fees, and global connectivity.

### Basic usage

```bash
python generate_cfmm_dataset.py \
  --n-tokens 128 --m-pools 4000 \
  --ratio-product 0.35 --ratio-weighted 0.55 --ratio-sum 0.10 \
  --pair-prob 0.75 --weighted-arities 3 4 5 \
  --reserve-scale-min 2e4 --reserve-scale-max 5e6 \
  --reserve-log-mean 5.2 --reserve-log-sigma 1.1 \
  --fee-tiers-bps 5 30 50 \
  --connectivity ring --extra-backbone-weight 1 \
  --seed 3407 \
  --task purchase --source-token 0 --target-token 5 \
  --amount-grid 0 200000 41 \
  --out input/huge128x4000.json
```

Key arguments:

* `--n-tokens`, `--m-pools`: specify network scale.
* `--ratio-product`, `--ratio-weighted`, `--ratio-sum`: mixture of constant-product, weighted, and constant-sum pools. The script renormalises the values to create a probability simplex.
* `--pair-prob`, `--max-arity-nonweighted`, `--weighted-arities`: control pool arity (number of assets per pool).
* `--reserve-*` flags: determine the depth and dispersion of pool reserves via lognormal sampling and global scaling.
* `--fee-*` flags: choose fee ranges or discrete fee tiers (expressed in basis points). Fees are converted to the `gamma = 1 - fee` coefficient used by the solver.
* `--connectivity`, `--extra-backbone-weight`: optionally add guaranteed ring or backbone edges between consecutive tokens to keep the network connected.
* `--task`, `--source-token`, `--target-token`, `--amount-grid`: embed experiment metadata to guide downstream optimisation tasks such as liquidation or purchase scenarios.
* `--save-npz`: emit an additional compressed NumPy archive containing the same information with ragged arrays stored as `dtype=object` for convenient loading in numerical workflows.

The resulting JSON contains:

```json
{
  "n_tokens": 128,
  "m_pools": 4000,
  "global_indices": [0, 1, ...],
  "local_indices": [[0, 7], [1, 5, 9], ...],
  "reserves": [[...], ...],
  "fees": [0.999, ...],
  "pool_types": ["product", "weighted", ...],
  "weights": [[...], null, ...],
  "experiment": {
    "task": "purchase",
    "source_token": 0,
    "target_token": 5,
    "amount_grid": {"start": 0.0, "stop": 200000.0, "num": 41}
  }
}
```

Only weighted pools include the `weights` entry; non-weighted pools set it to `null`.

## Solving the routing problem

[`large_example.py`](large_example.py) demonstrates how to load a dataset and solve a liquidation-style routing problem using CVXPY:

1. Load the dataset and extract arrays for pool topology (`local_indices`), reserves, fees (`gamma = 1 - fee`), pool types, and per-pool weights.
2. Build selection matrices `A_i` mapping local pool coordinates to the global token space.
3. Introduce non-negative decision variables `Δ` and `Λ` for each pool to model token inflows and outflows.
4. Aggregate the net trade vector `Ψ` and initialise the desired starting inventory (e.g., sell `t` units of the source token).
5. Define post-trade reserves `R' = R + γΔ − Λ` and enforce pool-specific convex constraints:
   * Constant-product pools preserve the product of reserves (via logarithms).
   * Weighted pools preserve a weighted sum of logarithms (geometric mean constraint).
   * Constant-sum pools preserve the sum of reserves.
6. Maximise the amount of target token received (`Ψ[target_token]`) subject to feasibility.

Run the example with:

```bash
python large_example.py
```

By default the script uses MOSEK. Swap `cp.MOSEK` for `cp.SCS`, `cp.ECOS`, or `cp.CLARABEL` to try other solvers. When using first-order solvers such as ECOS, you may need to rescale reserves to improve numerical conditioning—the script contains commented code showing the required scaling operations.

The script prints the maximum amount of the target token achievable from the specified trade size.

## Visualising solver behaviour

The repository captures convergence tables from multiple solvers and provides dedicated plotting scripts:

* `plot_iter_cla.py`: Clarabel iteration history.
* `plot_iter_ecos.py`: ECOS iteration history.
* `plot_iter_scs.py`: SCS iteration history.
* `plot_iter_mosek.py`: MOSEK iteration history.

Each script embeds the raw solver console output for several dataset scales, parses the textual logs with regular expressions, and produces publication-ready plots showing the evolution of primal/dual costs, residuals, and barrier parameters across iterations. Running a script creates a PDF in the current directory (also stored under `output/`) and opens the figure in an interactive window if a GUI backend is available:

```bash
python plot_iter_ecos.py
```

`compare.py` focuses on wall-clock performance. It encodes benchmark runtimes (in seconds) for Clarabel, SCS, ECOS, and MOSEK across problem sizes ranging from `8×12` to `128×4000`. The script draws a main plot plus an inset that zooms into the smaller regimes, then saves the resulting figure as `solver_runtime_vs_size_0.pdf`.

## Working with the provided datasets

The `input/` directory bundles several ready-to-use datasets at different scales (e.g., `huge8x12.json`, `huge32x100.json`, `huge128x4000.json`). Point `large_example.py` or your own experiments to these files to reproduce the benchmarks without running the generator.

Generated figures are cached in `output/` for reference. You can overwrite them by rerunning the plotting scripts.

## Reproducibility tips

* Always set `--seed` when generating datasets to guarantee identical pool realisations across runs.
* Store the exact solver and version used for optimisation; results from first-order methods can vary with solver tolerances. CVXPY lets you control tolerances via keyword arguments to `Problem.solve()`.
* For large-scale problems solved with first-order methods, experiment with the scaling snippet provided in `large_example.py` to improve convergence.
* When comparing solver performance, record both iteration counts and runtime to distinguish convergence speed from per-iteration cost.